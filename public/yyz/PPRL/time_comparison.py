#!/usr/bin/env python3
"""
Training Time Comparison: Pre-trained 200 episodes vs Zero Bubble
è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼šé¢„è®­ç»ƒ200è½® vs Zero Bubble

æµ‹è¯•å¤§è§„æ¨¡é…ç½®ï¼š
- 20ä¸ªè®¾å¤‡
- 30ä¸ªmicro-batch
- å¯¹æ¯”è®­ç»ƒæ—¶é—´å’Œæ€§èƒ½
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import os
import time
from pipeline_simulator import PipelineSimulator, TimeModel
from zero_bubble_scheduler import ZeroBubbleScheduler
from ppo_scheduler import PPOScheduler


def train_ppo_model(simulator, model_path="ppo_model.pth", num_episodes=200):
    """
    è®­ç»ƒPPOæ¨¡å‹å¹¶ä¿å­˜
    
    Args:
        simulator: æµæ°´çº¿ä»¿çœŸå™¨
        model_path: æ¨¡å‹ä¿å­˜è·¯å¾„
        num_episodes: è®­ç»ƒè½®æ•°
    """
    print(f"Training PPO model for {num_episodes} episodes...")
    
    ppo_scheduler = PPOScheduler(simulator)
    episode_rewards = ppo_scheduler.train(num_episodes=num_episodes, update_frequency=20)
    
    # ä¿å­˜æ¨¡å‹
    torch.save(ppo_scheduler.agent.state_dict(), model_path)
    print(f"Model saved to {model_path}")
    
    return ppo_scheduler, episode_rewards


def load_ppo_model(simulator, model_path="ppo_model.pth"):
    """
    åŠ è½½é¢„è®­ç»ƒçš„PPOæ¨¡å‹
    
    Args:
        simulator: æµæ°´çº¿ä»¿çœŸå™¨
        model_path: æ¨¡å‹è·¯å¾„
        
    Returns:
        PPOScheduler: åŠ è½½äº†é¢„è®­ç»ƒæ¨¡å‹çš„è°ƒåº¦å™¨
    """
    ppo_scheduler = PPOScheduler(simulator)
    
    if os.path.exists(model_path):
        ppo_scheduler.agent.load_state_dict(torch.load(model_path))
        print(f"Loaded pre-trained model from {model_path}")
    else:
        print(f"Model file {model_path} not found, using untrained model")
    
    return ppo_scheduler


def run_time_comparison():
    """
    è¿è¡Œè®­ç»ƒæ—¶é—´å¯¹æ¯”å®éªŒ
    
    å¯¹æ¯”ä¸¤ç§æ–¹æ³•ï¼š
    1. Zero Bubbleï¼ˆæ— è®­ç»ƒæ—¶é—´ï¼‰
    2. é¢„è®­ç»ƒ200è½®ï¼ˆæœ‰è®­ç»ƒæ—¶é—´ï¼‰
    """
    print("Training Time Comparison: Pre-trained 200 episodes vs Zero Bubble")
    print("=" * 80)
    print("Large Scale Configuration: 20 devices, 30 micro-batches")
    print("=" * 80)
    
    # å¤§è§„æ¨¡å®éªŒé…ç½®
    num_devices = 20
    num_micro_batches = 30
    micro_batch_size = 32
    noise_levels = [0.0, 0.1, 0.2, 0.3]  # 0%, 10%, 20%, 30%æ³¢åŠ¨
    num_trials = 3  # å‡å°‘è¯•éªŒæ¬¡æ•°ä»¥åŠ å¿«é€Ÿåº¦
    
    # å­˜å‚¨ç»“æœ
    results = {
        'noise_levels': noise_levels,
        'zero_bubble_times': [],
        'pretrain_200_times': [],
        'zero_bubble_throughputs': [],
        'pretrain_200_throughputs': [],
        'training_times': [],
        'total_operations': num_devices * num_micro_batches * 3
    }
    
    print(f"Problem Scale: {num_devices} devices Ã— {num_micro_batches} micro-batches = {results['total_operations']} operations")
    
    # ä¸ºæ¯ä¸ªå™ªå£°æ°´å¹³è®­ç»ƒé¢„è®­ç»ƒæ¨¡å‹
    print("\n" + "="*60)
    print("STEP 1: Training pre-trained models for each noise level")
    print("="*60)
    
    pretrained_models = {}
    training_times = {}
    
    for noise_level in noise_levels:
        print(f"\nTraining pre-trained model for {noise_level*100:.0f}% noise...")
        
        time_model = TimeModel(
            base_compute_time=1.0,
            base_comm_time=0.5,
            noise_level=noise_level,
            seed=42
        )
        
        simulator = PipelineSimulator(
            num_devices=num_devices,
            num_micro_batches=num_micro_batches,
            micro_batch_size=micro_batch_size,
            time_model=time_model
        )
        
        # è®­ç»ƒ200è½®é¢„è®­ç»ƒæ¨¡å‹å¹¶è®°å½•æ—¶é—´
        model_path = f"/data/public/yyz/PPRL/ppo_model_large_{int(noise_level*100)}_200.pth"
        
        start_time = time.time()
        ppo_scheduler, training_rewards = train_ppo_model(
            simulator, 
            model_path=model_path,
            num_episodes=200
        )
        training_time = time.time() - start_time
        
        pretrained_models[noise_level] = model_path
        training_times[noise_level] = training_time
        
        print(f"200-episode model saved to {model_path}")
        print(f"Training completed in {training_time:.2f} seconds")
        print(f"Final average reward: {np.mean(training_rewards[-10:]):.2f}")
    
    # å¯¹æ¯ä¸ªå™ªå£°æ°´å¹³è¿›è¡Œæµ‹è¯•
    for noise_level in noise_levels:
        print(f"\n" + "="*60)
        print(f"Testing with {noise_level*100:.0f}% noise level...")
        print(f"Running {num_trials} trials for each algorithm...")
        print("="*60)
        
        # å­˜å‚¨å¤šæ¬¡è¯•éªŒçš„ç»“æœ
        zb_times = []
        pretrain_200_times = []
        zb_throughputs = []
        pretrain_200_throughputs = []
        
        for trial in range(num_trials):
            print(f"  Trial {trial + 1}/{num_trials}:")
            
            # åˆ›å»ºæ—¶é—´æ¨¡å‹ï¼ˆä½¿ç”¨ä¸åŒçš„ç§å­ï¼‰
            time_model = TimeModel(
                base_compute_time=1.0,
                base_comm_time=0.5,
                noise_level=noise_level,
                seed=42 + trial
            )
            
            # 1. Zero Bubbleè°ƒåº¦ï¼ˆåŸºå‡†ï¼‰
            print("    Running Zero Bubble scheduler...")
            start_time = time.time()
            zb_sim = PipelineSimulator(
                num_devices=num_devices,
                num_micro_batches=num_micro_batches,
                micro_batch_size=micro_batch_size,
                time_model=time_model
            )
            zb_scheduler = ZeroBubbleScheduler(zb_sim)
            zb_result = zb_scheduler.schedule()
            zb_execution_time = time.time() - start_time
            
            zb_times.append(zb_result['total_time'])
            zb_throughputs.append(zb_result['throughput'])
            print(f"      Zero Bubble execution time: {zb_execution_time:.2f}s")
            
            # 2. é¢„è®­ç»ƒ200è½®
            print("    Running PPO scheduler (pre-trained 200)...")
            start_time = time.time()
            pretrain_200_sim = PipelineSimulator(
                num_devices=num_devices,
                num_micro_batches=num_micro_batches,
                micro_batch_size=micro_batch_size,
                time_model=time_model
            )
            pretrain_200_scheduler = load_ppo_model(pretrain_200_sim, pretrained_models[noise_level])
            pretrain_200_result = pretrain_200_scheduler.schedule()
            pretrain_execution_time = time.time() - start_time
            
            pretrain_200_times.append(pretrain_200_result['total_time'])
            pretrain_200_throughputs.append(pretrain_200_result['throughput'])
            print(f"      Pre-trained execution time: {pretrain_execution_time:.2f}s")
        
        # è®¡ç®—å¹³å‡å€¼
        avg_zb_time = np.mean(zb_times)
        avg_pretrain_200_time = np.mean(pretrain_200_times)
        avg_zb_throughput = np.mean(zb_throughputs)
        avg_pretrain_200_throughput = np.mean(pretrain_200_throughputs)
        
        # å­˜å‚¨å¹³å‡ç»“æœ
        results['zero_bubble_times'].append(avg_zb_time)
        results['pretrain_200_times'].append(avg_pretrain_200_time)
        results['zero_bubble_throughputs'].append(avg_zb_throughput)
        results['pretrain_200_throughputs'].append(avg_pretrain_200_throughput)
        results['training_times'].append(training_times[noise_level])
        
        # æ‰“å°å½“å‰ç»“æœ
        print(f"    Average Results:")
        print(f"      Zero Bubble:      {avg_zb_time:.2f}s, Throughput: {avg_zb_throughput:.4f}")
        print(f"      Pre-train(200):   {avg_pretrain_200_time:.2f}s, Throughput: {avg_pretrain_200_throughput:.4f}")
        
        # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
        pretrain_200_improvement = (avg_zb_time - avg_pretrain_200_time) / avg_zb_time * 100
        print(f"      Improvement: Pre-train(200) {pretrain_200_improvement:.1f}%")
        print(f"      Training time: {training_times[noise_level]:.2f}s")
    
    # ç»˜åˆ¶ç»“æœå›¾è¡¨
    plot_time_comparison_results(results)
    
    # æ‰“å°è¯¦ç»†åˆ†æ
    print_time_analysis(results)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    print("\nCleaning up temporary model files...")
    for noise_level in noise_levels:
        model_path = f"/data/public/yyz/PPRL/ppo_model_large_{int(noise_level*100)}_200.pth"
        if os.path.exists(model_path):
            os.remove(model_path)
            print(f"Removed {model_path}")
    print("Cleanup completed.")


def plot_time_comparison_results(results):
    """
    ç»˜åˆ¶è®­ç»ƒæ—¶é—´å¯¹æ¯”ç»“æœå›¾è¡¨
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    noise_levels = results['noise_levels']
    
    # 1. æ€»æ‰§è¡Œæ—¶é—´å¯¹æ¯”
    ax1.plot(noise_levels, results['zero_bubble_times'], 'o-', 
             label='Zero Bubble', linewidth=2, markersize=8)
    ax1.plot(noise_levels, results['pretrain_200_times'], '^-', 
             label='Pre-train(200)', linewidth=2, markersize=8)
    ax1.set_xlabel('Noise Level')
    ax1.set_ylabel('Total Execution Time (s)')
    ax1.set_title('Execution Time vs Noise Level')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ååé‡å¯¹æ¯”
    ax2.plot(noise_levels, results['zero_bubble_throughputs'], 'o-', 
             label='Zero Bubble', linewidth=2, markersize=8)
    ax2.plot(noise_levels, results['pretrain_200_throughputs'], '^-', 
             label='Pre-train(200)', linewidth=2, markersize=8)
    ax2.set_xlabel('Noise Level')
    ax2.set_ylabel('Throughput (micro-batches/s)')
    ax2.set_title('Throughput vs Noise Level')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. è®­ç»ƒæ—¶é—´
    ax3.bar([f"{int(nl*100)}%" for nl in noise_levels], results['training_times'], 
            color='skyblue', alpha=0.7)
    ax3.set_xlabel('Noise Level')
    ax3.set_ylabel('Training Time (s)')
    ax3.set_title('PPO Training Time by Noise Level')
    ax3.grid(True, alpha=0.3)
    
    # 4. æ€§èƒ½æ”¹è¿› vs è®­ç»ƒæ—¶é—´
    improvements = []
    for i, noise_level in enumerate(noise_levels):
        zb_time = results['zero_bubble_times'][i]
        pretrain_time = results['pretrain_200_times'][i]
        improvement = (zb_time - pretrain_time) / zb_time * 100
        improvements.append(improvement)
    
    ax4.scatter(results['training_times'], improvements, s=100, alpha=0.7)
    for i, noise_level in enumerate(noise_levels):
        ax4.annotate(f"{int(noise_level*100)}%", 
                    (results['training_times'][i], improvements[i]),
                    xytext=(5, 5), textcoords='offset points')
    ax4.set_xlabel('Training Time (s)')
    ax4.set_ylabel('Performance Improvement (%)')
    ax4.set_title('Training Time vs Performance Improvement')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('time_comparison_large_scale.png', dpi=300, bbox_inches='tight')
    plt.show()


def print_time_analysis(results):
    """
    æ‰“å°è®­ç»ƒæ—¶é—´åˆ†æç»“æœ
    """
    print("\n" + "=" * 100)
    print("TRAINING TIME ANALYSIS: Large Scale (20 devices, 30 micro-batches)")
    print("=" * 100)
    
    noise_levels = results['noise_levels']
    
    # åˆ›å»ºç»“æœè¡¨æ ¼
    print(f"\n{'Noise':<8} {'Zero Bubble':<12} {'Pre-train(200)':<12} {'Improvement':<12} {'Training Time':<12}")
    print(f"{'Level':<8} {'Time (s)':<12} {'Time (s)':<12} {'(%)':<12} {'(s)':<12}")
    print("-" * 100)
    
    for i, noise_level in enumerate(noise_levels):
        zb_time = results['zero_bubble_times'][i]
        pretrain_time = results['pretrain_200_times'][i]
        training_time = results['training_times'][i]
        
        improvement = (zb_time - pretrain_time) / zb_time * 100
        
        print(f"{noise_level*100:>6.0f}% {zb_time:>10.2f} {pretrain_time:>10.2f} "
              f"{improvement:>10.1f}% {training_time:>10.1f}")
    
    # ç»Ÿè®¡åˆ†æ
    print(f"\n{'='*80}")
    print("STATISTICAL ANALYSIS")
    print(f"{'='*80}")
    
    # è®¡ç®—å¹³å‡æ”¹è¿›
    avg_improvement = np.mean([
        (results['zero_bubble_times'][i] - results['pretrain_200_times'][i]) / 
        results['zero_bubble_times'][i] * 100
        for i in range(len(noise_levels))
    ])
    
    # è®¡ç®—å¹³å‡è®­ç»ƒæ—¶é—´
    avg_training_time = np.mean(results['training_times'])
    
    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    total_training_time = sum(results['training_times'])
    
    print(f"Average improvement of Pre-train(200) over Zero Bubble: {avg_improvement:.2f}%")
    print(f"Average training time per noise level: {avg_training_time:.2f}s")
    print(f"Total training time for all noise levels: {total_training_time:.2f}s")
    print(f"Problem scale: {results['total_operations']} operations")
    
    # æ•ˆç‡åˆ†æ
    print(f"\n{'='*80}")
    print("EFFICIENCY ANALYSIS")
    print(f"{'='*80}")
    
    print(f"Training time per operation: {total_training_time / results['total_operations']:.6f}s")
    print(f"Training time per device: {total_training_time / 20:.2f}s")
    print(f"Training time per micro-batch: {total_training_time / 30:.2f}s")
    
    # æˆæœ¬æ•ˆç›Šåˆ†æ
    print(f"\n{'='*80}")
    print("COST-BENEFIT ANALYSIS")
    print(f"{'='*80}")
    
    if avg_improvement > 0:
        print(f"âœ… Pre-train(200) provides {avg_improvement:.2f}% performance improvement")
        print(f"   Training cost: {total_training_time:.2f}s")
        print(f"   Performance gain: {avg_improvement:.2f}%")
        print(f"   Cost per 1% improvement: {total_training_time / avg_improvement:.2f}s")
    else:
        print(f"âŒ Pre-train(200) does not provide performance improvement")
        print(f"   Training cost: {total_training_time:.2f}s (wasted)")
    
    print(f"\nğŸ“Š Results saved to 'time_comparison_large_scale.png'")


if __name__ == "__main__":
    run_time_comparison()
